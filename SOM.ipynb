{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "887M5QqdtkB5"
   },
   "source": [
    "Taking from https://github.com/lyes-khacef/GPU-SOM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63Jq-pQyzU2M"
   },
   "source": [
    "Now mixing it up with data from a notebook in the ChaosDoc folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6HE59u21zTIk"
   },
   "source": [
    "## 1. Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQCjVQQKzFML"
   },
   "source": [
    "### GPUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fRC7-Z8qsbW9",
    "outputId": "1ee19d8a-a966-418f-e36e-0c60887352d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: GPUtil in d:\\progs\\miniconda3\\lib\\site-packages (1.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install GPUtil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QOp27HwhuPxD"
   },
   "source": [
    "### From imports.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: humanize in d:\\progs\\miniconda3\\lib\\site-packages (4.9.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install humanize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OgBbUj5xsn7s",
    "outputId": "42167ba7-0470-4045-85bf-7e59d51b7afa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version =  2.16.1\n",
      "Eager execution!\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import timeit\n",
    "\n",
    "# import packages\n",
    "import os, sys, humanize, psutil, GPUtil\n",
    "\n",
    "# diable gpu\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"\n",
    "\n",
    "# disable tensorflow logs\n",
    "\"\"\"\n",
    "0 = all messages are logged (default behavior)\n",
    "1 = INFO messages are not printed\n",
    "2 = INFO and WARNING messages are not printed\n",
    "3 = INFO, WARNING, and ERROR messages are not printed\n",
    "\"\"\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "\n",
    "# import tensorflow\n",
    "import tensorflow as tf\n",
    "print(\"Tensorflow version = \", tf.__version__)\n",
    "if tf.executing_eagerly():\n",
    "    print(\"Eager execution!\")\n",
    "#tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s29VW9OQuKLA"
   },
   "source": [
    "### From gpu_check.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8xA9Nh8YtqtH"
   },
   "source": [
    "Check for GPUs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uCsHSAelsti6",
    "outputId": "7d2c0bf3-3af6-4ea7-db28-54e15fb0c814"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU RAM Free: 1.4 GB\n",
      "[<GPUtil.GPUtil.GPU object at 0x000002557D8A3510>]\n",
      "GPU 0 ... Mem Free: 4021MB / 4096MB | Utilization   2%\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "#from imports import *\n",
    "\n",
    "# define function\n",
    "def gpu_report():\n",
    "    print(\"CPU RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ))\n",
    "    GPUs = GPUtil.getGPUs()\n",
    "    print(GPUs)\n",
    "    for i, gpu in enumerate(GPUs):\n",
    "        print('GPU {:d} ... Mem Free: {:.0f}MB / {:.0f}MB | Utilization {:3.0f}%'.format(i, gpu.memoryFree, gpu.memoryTotal, gpu.memoryUtil*100))\n",
    "\n",
    "# GPU memory check\n",
    "gpu_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9aKLEdkJybYY"
   },
   "source": [
    "## 2. Uploading file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "GlrLHp6tBMUL"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "pt0rj9Zlzg2l"
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_fwf(\n",
    "    '..\\ChaosDoc\\e_composite_im7_8552_OHT_b-OHT-Hard-J3-ExpRed_S11.csv',\n",
    "    header=[1,2,3],\n",
    "    skip_blank_lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "eJMupLwW1vFu"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0_level_0</th>\n",
       "      <th>HT-QI-1 E: 8 IP:</th>\n",
       "      <th>HT-QI-1 E: 9 IP:</th>\n",
       "      <th>HT-QI-1 E: 10 IP:</th>\n",
       "      <th>HT-QI-1 E: 11 IP:</th>\n",
       "      <th>HT-QI-1 E: 12 IP:</th>\n",
       "      <th>HT-QI-1 E: 13 IP:</th>\n",
       "      <th>HT-QI-1 E: 14 IP:</th>\n",
       "      <th>HT-QI-1 E: 15 IP:</th>\n",
       "      <th>HT-QI-1 E: 16 IP:</th>\n",
       "      <th>...</th>\n",
       "      <th>HT-QI-1 E: 29175</th>\n",
       "      <th>HT-QI-1 E: 29176</th>\n",
       "      <th>HT-QI-1 E: 29177</th>\n",
       "      <th>HT-QI-1 E: 29178</th>\n",
       "      <th>HT-QI-1 E: 29179</th>\n",
       "      <th>HT-QI-1 E: 29180</th>\n",
       "      <th>HT-QI-1 E: 29181</th>\n",
       "      <th>HT-QI-1 E: 29182</th>\n",
       "      <th>HT-QI-1 E: 29183</th>\n",
       "      <th>HT-QI-1 E: 29184</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>1_1</th>\n",
       "      <th>1_1</th>\n",
       "      <th>1_1</th>\n",
       "      <th>1_1</th>\n",
       "      <th>1_1</th>\n",
       "      <th>1_1</th>\n",
       "      <th>1_1</th>\n",
       "      <th>1_1</th>\n",
       "      <th>1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>IP: 1</th>\n",
       "      <th>IP: 1</th>\n",
       "      <th>IP: 1</th>\n",
       "      <th>IP: 1</th>\n",
       "      <th>IP: 1</th>\n",
       "      <th>IP: 1</th>\n",
       "      <th>IP: 1</th>\n",
       "      <th>IP: 1</th>\n",
       "      <th>IP: 1</th>\n",
       "      <th>IP: 1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>0.</th>\n",
       "      <th>0.</th>\n",
       "      <th>0.</th>\n",
       "      <th>0.</th>\n",
       "      <th>0.</th>\n",
       "      <th>0.</th>\n",
       "      <th>0.</th>\n",
       "      <th>0.</th>\n",
       "      <th>0.</th>\n",
       "      <th>0.</th>\n",
       "      <th>...</th>\n",
       "      <th>0.</th>\n",
       "      <th>0.</th>\n",
       "      <th>0.</th>\n",
       "      <th>0.</th>\n",
       "      <th>0.</th>\n",
       "      <th>0.</th>\n",
       "      <th>0.</th>\n",
       "      <th>0.</th>\n",
       "      <th>0.</th>\n",
       "      <th>0.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.990001</td>\n",
       "      <td>133.519</td>\n",
       "      <td>-24.4072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9959</td>\n",
       "      <td>191.6630</td>\n",
       "      <td>-17.3185</td>\n",
       "      <td>81.6221</td>\n",
       "      <td>...</td>\n",
       "      <td>298.0950</td>\n",
       "      <td>255.753</td>\n",
       "      <td>220.733</td>\n",
       "      <td>158.3860</td>\n",
       "      <td>138.82800</td>\n",
       "      <td>129.3100</td>\n",
       "      <td>155.65000</td>\n",
       "      <td>170.6290</td>\n",
       "      <td>165.1450</td>\n",
       "      <td>243.39600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.992501</td>\n",
       "      <td>291.847</td>\n",
       "      <td>-179.8790</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-41.6184</td>\n",
       "      <td>185.0340</td>\n",
       "      <td>-54.6097</td>\n",
       "      <td>140.0470</td>\n",
       "      <td>...</td>\n",
       "      <td>277.0270</td>\n",
       "      <td>237.037</td>\n",
       "      <td>181.902</td>\n",
       "      <td>114.5620</td>\n",
       "      <td>78.68400</td>\n",
       "      <td>51.3064</td>\n",
       "      <td>66.36730</td>\n",
       "      <td>73.7682</td>\n",
       "      <td>84.1089</td>\n",
       "      <td>91.47400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0.995001</td>\n",
       "      <td>154.215</td>\n",
       "      <td>-133.3700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>114.8270</td>\n",
       "      <td>80.8693</td>\n",
       "      <td>-113.2060</td>\n",
       "      <td>153.5350</td>\n",
       "      <td>...</td>\n",
       "      <td>213.1710</td>\n",
       "      <td>198.602</td>\n",
       "      <td>158.115</td>\n",
       "      <td>51.5597</td>\n",
       "      <td>24.91220</td>\n",
       "      <td>64.0220</td>\n",
       "      <td>7.43712</td>\n",
       "      <td>-39.1197</td>\n",
       "      <td>-45.4398</td>\n",
       "      <td>4.77277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.997501</td>\n",
       "      <td>114.661</td>\n",
       "      <td>134.7000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-130.0630</td>\n",
       "      <td>101.9100</td>\n",
       "      <td>43.0402</td>\n",
       "      <td>123.6190</td>\n",
       "      <td>...</td>\n",
       "      <td>138.5300</td>\n",
       "      <td>115.482</td>\n",
       "      <td>116.748</td>\n",
       "      <td>74.6318</td>\n",
       "      <td>52.53810</td>\n",
       "      <td>-13.4246</td>\n",
       "      <td>-58.97490</td>\n",
       "      <td>-131.4770</td>\n",
       "      <td>-137.4010</td>\n",
       "      <td>-131.60400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>186.735</td>\n",
       "      <td>-137.9610</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-142.5160</td>\n",
       "      <td>-63.4698</td>\n",
       "      <td>-150.5360</td>\n",
       "      <td>30.7806</td>\n",
       "      <td>...</td>\n",
       "      <td>25.3721</td>\n",
       "      <td>39.253</td>\n",
       "      <td>68.593</td>\n",
       "      <td>85.0660</td>\n",
       "      <td>-5.96922</td>\n",
       "      <td>-61.1174</td>\n",
       "      <td>-141.36800</td>\n",
       "      <td>-156.0400</td>\n",
       "      <td>-206.3100</td>\n",
       "      <td>-207.98900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0_level_0 HT-QI-1 E: 8 IP: HT-QI-1 E: 9 IP: HT-QI-1 E: 10 IP:  \\\n",
       "                     X              1_1              1_1               1_1   \n",
       "                    0.               0.               0.                0.   \n",
       "395           0.990001          133.519         -24.4072               0.0   \n",
       "396           0.992501          291.847        -179.8790               0.0   \n",
       "397           0.995001          154.215        -133.3700               0.0   \n",
       "398           0.997501          114.661         134.7000               0.0   \n",
       "399           1.000000          186.735        -137.9610               0.0   \n",
       "\n",
       "    HT-QI-1 E: 11 IP: HT-QI-1 E: 12 IP: HT-QI-1 E: 13 IP: HT-QI-1 E: 14 IP:  \\\n",
       "                  1_1               1_1               1_1               1_1   \n",
       "                   0.                0.                0.                0.   \n",
       "395               0.0               0.0           12.9959          191.6630   \n",
       "396               0.0               0.0          -41.6184          185.0340   \n",
       "397               0.0               0.0          114.8270           80.8693   \n",
       "398               0.0               0.0         -130.0630          101.9100   \n",
       "399               0.0               0.0         -142.5160          -63.4698   \n",
       "\n",
       "    HT-QI-1 E: 15 IP: HT-QI-1 E: 16 IP:  ... HT-QI-1 E: 29175  \\\n",
       "                  1_1               1_1  ...            IP: 1   \n",
       "                   0.                0.  ...               0.   \n",
       "395          -17.3185           81.6221  ...         298.0950   \n",
       "396          -54.6097          140.0470  ...         277.0270   \n",
       "397         -113.2060          153.5350  ...         213.1710   \n",
       "398           43.0402          123.6190  ...         138.5300   \n",
       "399         -150.5360           30.7806  ...          25.3721   \n",
       "\n",
       "    HT-QI-1 E: 29176 HT-QI-1 E: 29177 HT-QI-1 E: 29178 HT-QI-1 E: 29179  \\\n",
       "               IP: 1            IP: 1            IP: 1            IP: 1   \n",
       "                  0.               0.               0.               0.   \n",
       "395          255.753          220.733         158.3860        138.82800   \n",
       "396          237.037          181.902         114.5620         78.68400   \n",
       "397          198.602          158.115          51.5597         24.91220   \n",
       "398          115.482          116.748          74.6318         52.53810   \n",
       "399           39.253           68.593          85.0660         -5.96922   \n",
       "\n",
       "    HT-QI-1 E: 29180 HT-QI-1 E: 29181 HT-QI-1 E: 29182 HT-QI-1 E: 29183  \\\n",
       "               IP: 1            IP: 1            IP: 1            IP: 1   \n",
       "                  0.               0.               0.               0.   \n",
       "395         129.3100        155.65000         170.6290         165.1450   \n",
       "396          51.3064         66.36730          73.7682          84.1089   \n",
       "397          64.0220          7.43712         -39.1197         -45.4398   \n",
       "398         -13.4246        -58.97490        -131.4770        -137.4010   \n",
       "399         -61.1174       -141.36800        -156.0400        -206.3100   \n",
       "\n",
       "    HT-QI-1 E: 29184  \n",
       "               IP: 1  \n",
       "                  0.  \n",
       "395        243.39600  \n",
       "396         91.47400  \n",
       "397          4.77277  \n",
       "398       -131.60400  \n",
       "399       -207.98900  \n",
       "\n",
       "[5 rows x 8301 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DW2rV--hbJik"
   },
   "source": [
    "### Get Column names For further vizes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "lqz-gOW41xfN"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0_level_0</th>\n",
       "      <th>HT-QI-1 E: 8 IP:</th>\n",
       "      <th>HT-QI-1 E: 9 IP:</th>\n",
       "      <th>HT-QI-1 E: 10 IP:</th>\n",
       "      <th>HT-QI-1 E: 11 IP:</th>\n",
       "      <th>HT-QI-1 E: 12 IP:</th>\n",
       "      <th>HT-QI-1 E: 13 IP:</th>\n",
       "      <th>HT-QI-1 E: 14 IP:</th>\n",
       "      <th>HT-QI-1 E: 15 IP:</th>\n",
       "      <th>HT-QI-1 E: 16 IP:</th>\n",
       "      <th>...</th>\n",
       "      <th>HT-QI-1 E: 29175</th>\n",
       "      <th>HT-QI-1 E: 29176</th>\n",
       "      <th>HT-QI-1 E: 29177</th>\n",
       "      <th>HT-QI-1 E: 29178</th>\n",
       "      <th>HT-QI-1 E: 29179</th>\n",
       "      <th>HT-QI-1 E: 29180</th>\n",
       "      <th>HT-QI-1 E: 29181</th>\n",
       "      <th>HT-QI-1 E: 29182</th>\n",
       "      <th>HT-QI-1 E: 29183</th>\n",
       "      <th>HT-QI-1 E: 29184</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>1_1</th>\n",
       "      <th>1_1</th>\n",
       "      <th>1_1</th>\n",
       "      <th>1_1</th>\n",
       "      <th>1_1</th>\n",
       "      <th>1_1</th>\n",
       "      <th>1_1</th>\n",
       "      <th>1_1</th>\n",
       "      <th>1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>IP: 1</th>\n",
       "      <th>IP: 1</th>\n",
       "      <th>IP: 1</th>\n",
       "      <th>IP: 1</th>\n",
       "      <th>IP: 1</th>\n",
       "      <th>IP: 1</th>\n",
       "      <th>IP: 1</th>\n",
       "      <th>IP: 1</th>\n",
       "      <th>IP: 1</th>\n",
       "      <th>IP: 1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>0.</th>\n",
       "      <th>0.</th>\n",
       "      <th>0.</th>\n",
       "      <th>0.</th>\n",
       "      <th>0.</th>\n",
       "      <th>0.</th>\n",
       "      <th>0.</th>\n",
       "      <th>0.</th>\n",
       "      <th>0.</th>\n",
       "      <th>0.</th>\n",
       "      <th>...</th>\n",
       "      <th>0.</th>\n",
       "      <th>0.</th>\n",
       "      <th>0.</th>\n",
       "      <th>0.</th>\n",
       "      <th>0.</th>\n",
       "      <th>0.</th>\n",
       "      <th>0.</th>\n",
       "      <th>0.</th>\n",
       "      <th>0.</th>\n",
       "      <th>0.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002532</td>\n",
       "      <td>2.048190e-20</td>\n",
       "      <td>-7.853190e-22</td>\n",
       "      <td>2.542990e-23</td>\n",
       "      <td>-6.882300e-25</td>\n",
       "      <td>1.535350e-26</td>\n",
       "      <td>-2.770790e-28</td>\n",
       "      <td>3.935010e-30</td>\n",
       "      <td>-4.257880e-32</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005078</td>\n",
       "      <td>8.071190e-10</td>\n",
       "      <td>-3.565360e-10</td>\n",
       "      <td>1.344670e-10</td>\n",
       "      <td>-4.402200e-11</td>\n",
       "      <td>1.266020e-11</td>\n",
       "      <td>-3.227390e-12</td>\n",
       "      <td>7.345170e-13</td>\n",
       "      <td>-1.502870e-13</td>\n",
       "      <td>2.930350e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.963290e-25</td>\n",
       "      <td>8.073150e-24</td>\n",
       "      <td>-1.009700e-22</td>\n",
       "      <td>1.167950e-21</td>\n",
       "      <td>-1.251430e-20</td>\n",
       "      <td>1.245040e-19</td>\n",
       "      <td>-1.154910e-18</td>\n",
       "      <td>1.006950e-17</td>\n",
       "      <td>-8.400920e-17</td>\n",
       "      <td>6.970990e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007536</td>\n",
       "      <td>3.221980e-09</td>\n",
       "      <td>-1.188120e-09</td>\n",
       "      <td>-2.738330e-10</td>\n",
       "      <td>1.312070e-09</td>\n",
       "      <td>-1.882750e-09</td>\n",
       "      <td>1.849990e-09</td>\n",
       "      <td>-1.297790e-09</td>\n",
       "      <td>5.523820e-10</td>\n",
       "      <td>2.424290e-11</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.635880e-14</td>\n",
       "      <td>9.072540e-14</td>\n",
       "      <td>-2.856260e-13</td>\n",
       "      <td>8.174030e-13</td>\n",
       "      <td>-2.109030e-12</td>\n",
       "      <td>4.849380e-12</td>\n",
       "      <td>-9.755110e-12</td>\n",
       "      <td>1.657490e-11</td>\n",
       "      <td>-2.174300e-11</td>\n",
       "      <td>1.241110e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010070</td>\n",
       "      <td>-2.860480e-09</td>\n",
       "      <td>5.423090e-09</td>\n",
       "      <td>-4.776170e-09</td>\n",
       "      <td>2.704060e-09</td>\n",
       "      <td>-7.542810e-10</td>\n",
       "      <td>-3.432600e-10</td>\n",
       "      <td>5.636890e-10</td>\n",
       "      <td>-1.914300e-10</td>\n",
       "      <td>-3.011000e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>1.860310e-11</td>\n",
       "      <td>-1.522860e-11</td>\n",
       "      <td>1.120750e-12</td>\n",
       "      <td>2.133880e-11</td>\n",
       "      <td>-4.397450e-11</td>\n",
       "      <td>5.851250e-11</td>\n",
       "      <td>-6.292270e-11</td>\n",
       "      <td>6.396460e-11</td>\n",
       "      <td>-6.287650e-11</td>\n",
       "      <td>3.974390e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.012523</td>\n",
       "      <td>-2.336160e-08</td>\n",
       "      <td>2.282460e-08</td>\n",
       "      <td>-1.311210e-08</td>\n",
       "      <td>1.556580e-09</td>\n",
       "      <td>4.253250e-09</td>\n",
       "      <td>-3.968160e-09</td>\n",
       "      <td>1.153980e-09</td>\n",
       "      <td>1.318310e-09</td>\n",
       "      <td>-3.043500e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>1.928290e-11</td>\n",
       "      <td>-2.900420e-11</td>\n",
       "      <td>4.344710e-11</td>\n",
       "      <td>-4.352690e-11</td>\n",
       "      <td>2.476230e-11</td>\n",
       "      <td>-1.908440e-11</td>\n",
       "      <td>-1.141100e-12</td>\n",
       "      <td>5.335240e-11</td>\n",
       "      <td>-6.085240e-11</td>\n",
       "      <td>3.863060e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0_level_0 HT-QI-1 E: 8 IP: HT-QI-1 E: 9 IP: HT-QI-1 E: 10 IP:  \\\n",
       "                   X              1_1              1_1               1_1   \n",
       "                  0.               0.               0.                0.   \n",
       "0           0.002532     2.048190e-20    -7.853190e-22      2.542990e-23   \n",
       "1           0.005078     8.071190e-10    -3.565360e-10      1.344670e-10   \n",
       "2           0.007536     3.221980e-09    -1.188120e-09     -2.738330e-10   \n",
       "3           0.010070    -2.860480e-09     5.423090e-09     -4.776170e-09   \n",
       "4           0.012523    -2.336160e-08     2.282460e-08     -1.311210e-08   \n",
       "\n",
       "  HT-QI-1 E: 11 IP: HT-QI-1 E: 12 IP: HT-QI-1 E: 13 IP: HT-QI-1 E: 14 IP:  \\\n",
       "                1_1               1_1               1_1               1_1   \n",
       "                 0.                0.                0.                0.   \n",
       "0     -6.882300e-25      1.535350e-26     -2.770790e-28      3.935010e-30   \n",
       "1     -4.402200e-11      1.266020e-11     -3.227390e-12      7.345170e-13   \n",
       "2      1.312070e-09     -1.882750e-09      1.849990e-09     -1.297790e-09   \n",
       "3      2.704060e-09     -7.542810e-10     -3.432600e-10      5.636890e-10   \n",
       "4      1.556580e-09      4.253250e-09     -3.968160e-09      1.153980e-09   \n",
       "\n",
       "  HT-QI-1 E: 15 IP: HT-QI-1 E: 16 IP:  ... HT-QI-1 E: 29175 HT-QI-1 E: 29176  \\\n",
       "                1_1               1_1  ...            IP: 1            IP: 1   \n",
       "                 0.                0.  ...               0.               0.   \n",
       "0     -4.257880e-32      0.000000e+00  ...     0.000000e+00     0.000000e+00   \n",
       "1     -1.502870e-13      2.930350e-14  ...    -5.963290e-25     8.073150e-24   \n",
       "2      5.523820e-10      2.424290e-11  ...    -2.635880e-14     9.072540e-14   \n",
       "3     -1.914300e-10     -3.011000e-10  ...     1.860310e-11    -1.522860e-11   \n",
       "4      1.318310e-09     -3.043500e-09  ...     1.928290e-11    -2.900420e-11   \n",
       "\n",
       "  HT-QI-1 E: 29177 HT-QI-1 E: 29178 HT-QI-1 E: 29179 HT-QI-1 E: 29180  \\\n",
       "             IP: 1            IP: 1            IP: 1            IP: 1   \n",
       "                0.               0.               0.               0.   \n",
       "0     0.000000e+00     0.000000e+00     0.000000e+00     0.000000e+00   \n",
       "1    -1.009700e-22     1.167950e-21    -1.251430e-20     1.245040e-19   \n",
       "2    -2.856260e-13     8.174030e-13    -2.109030e-12     4.849380e-12   \n",
       "3     1.120750e-12     2.133880e-11    -4.397450e-11     5.851250e-11   \n",
       "4     4.344710e-11    -4.352690e-11     2.476230e-11    -1.908440e-11   \n",
       "\n",
       "  HT-QI-1 E: 29181 HT-QI-1 E: 29182 HT-QI-1 E: 29183 HT-QI-1 E: 29184  \n",
       "             IP: 1            IP: 1            IP: 1            IP: 1  \n",
       "                0.               0.               0.               0.  \n",
       "0     0.000000e+00     0.000000e+00     0.000000e+00     0.000000e+00  \n",
       "1    -1.154910e-18     1.006950e-17    -8.400920e-17     6.970990e-16  \n",
       "2    -9.755110e-12     1.657490e-11    -2.174300e-11     1.241110e-11  \n",
       "3    -6.292270e-11     6.396460e-11    -6.287650e-11     3.974390e-11  \n",
       "4    -1.141100e-12     5.335240e-11    -6.085240e-11     3.863060e-10  \n",
       "\n",
       "[5 rows x 8301 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "d-NHF0OV4TXr"
   },
   "outputs": [],
   "source": [
    "npdf1 = np.array(df1[:400],dtype=float).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "jrJxigAO8fMK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8301, 400)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npdf1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9fjgBClYqe3_"
   },
   "source": [
    "# 3. Boilerplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASSJ_UW80c4P"
   },
   "source": [
    "### From data_load.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "70uOr3qV0eDz"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "#from imports import *\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# fuction to load data from file\n",
    "def load_data(name):\n",
    "    data = np.load(name, allow_pickle=True)\n",
    "    print(\"Data.shape = \", data.shape)\n",
    "    return data\n",
    "\n",
    "def get_dataset(train_data, label_data, test_data):\n",
    "    # importing dataset\n",
    "    (x_train_all, index_train_all), (x_test_all, index_test_all) = mnist.load_data()\n",
    "    x_train_all = x_train_all.astype('float32') / 255.\n",
    "    x_test_all = x_test_all.astype('float32') / 255.\n",
    "    x_train_all = x_train_all.reshape((60000, 784))\n",
    "    x_test_all = x_test_all.reshape((10000, 784))\n",
    "\n",
    "    # constructing dataset\n",
    "    x_train = np.copy(x_train_all[:train_data,:])\n",
    "    index_train = np.copy(index_train_all[:train_data])\n",
    "    x_label = np.copy(x_train_all[:label_data,:])\n",
    "    index_label = np.copy(index_train_all[:label_data])\n",
    "    x_test = np.copy(x_test_all[:test_data,:])\n",
    "    index_test = np.copy(index_test_all[:test_data])\n",
    "\n",
    "    return x_train, index_train, x_label, index_label, x_test, index_test, label_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W1TzQRWSzmEF"
   },
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZhC_hROXtd7w"
   },
   "source": [
    "### From file tf_ksom.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "DGgYl9QT9_gv"
   },
   "outputs": [],
   "source": [
    "class KSOM_3D():\n",
    "    def __init__(self, m, n, o, dim):\n",
    "        self.m = m\n",
    "        self.n = n\n",
    "        self.o = o\n",
    "        self.dim = dim\n",
    "        self.map_wgt =  tf.Variable(\n",
    "                            tf.random.uniform(\n",
    "                                shape = [m*n*o, dim],\n",
    "                                minval = 0.0,\n",
    "                                maxval = 1.0,\n",
    "                                dtype = tf.float32,\n",
    "                                seed = 23\n",
    "                            )\n",
    "                        )\n",
    "        self.map_loc =  tf.constant(\n",
    "                            np.array(\n",
    "                                list(self.neuron_locs(m, n, o))\n",
    "                            )\n",
    "                        )\n",
    "\n",
    "    def neuron_locs(self, m, n, o):\n",
    "        # nested iterations over both dimensions to yield one by one the 2-d locations of the individual neurons in the SOM\n",
    "        for i in range(m):\n",
    "            for j in range(n):\n",
    "                for k in range(o):\n",
    "                    yield np.array([i,j,k], dtype=np.float32)\n",
    "\n",
    "    def compute_winner(self, sample):\n",
    "            self.sample = sample\n",
    "\n",
    "            # compute the squared euclidean distance between the input and the neurons\n",
    "            self.squared_distance = tf.reduce_sum(\n",
    "                                        tf.square(\n",
    "                                            tf.subtract(\n",
    "                                                self.map_wgt, # [m*n*o, dim]\n",
    "                                                tf.expand_dims(\n",
    "                                                    self.sample, # [dim] -> [1, dim]\n",
    "                                                    axis=0\n",
    "                                                )\n",
    "                                            )\n",
    "                                        ),\n",
    "                                        axis=1\n",
    "                                    )\n",
    "\n",
    "            # find the bmu's index\n",
    "            self.bmu_idx =  tf.argmin(\n",
    "                                    input=self.squared_distance,\n",
    "                                    axis=0\n",
    "                                )\n",
    "\n",
    "            # extract the bmu's 2-d location\n",
    "            self.bmu_loc =  tf.gather(\n",
    "                                self.map_loc,\n",
    "                                self.bmu_idx\n",
    "                            )\n",
    "\n",
    "    def update_network(self, epsilon, eta):\n",
    "        # compute the squared manhattan distance between the bmu and the neurons\n",
    "        self.bmu_distance_squares = tf.reduce_sum(\n",
    "                                        tf.square(\n",
    "                                            tf.subtract(\n",
    "                                                self.map_loc, # [m*n*o, 2]\n",
    "                                                tf.expand_dims(\n",
    "                                                    self.bmu_loc, # [2] -> [1, 2]\n",
    "                                                    axis=0\n",
    "                                                )\n",
    "                                            )\n",
    "                                        ),\n",
    "                                        axis=1\n",
    "                                    )\n",
    "\n",
    "        # compute the neighborhood function\n",
    "        self.neighbourhood_func = tf.exp(\n",
    "                                      tf.negative(\n",
    "                                          tf.math.divide(\n",
    "                                              self.bmu_distance_squares,\n",
    "                                              tf.multiply(\n",
    "                                                  tf.square(\n",
    "                                                      eta,\n",
    "                                                  ),\n",
    "                                                  2.0\n",
    "                                              )\n",
    "                                          )\n",
    "                                      )\n",
    "                                  )\n",
    "\n",
    "        # compute the overall learning of each neuron\n",
    "        self.learning = tf.multiply(\n",
    "                            self.neighbourhood_func,\n",
    "                            epsilon\n",
    "                        )\n",
    "\n",
    "        # compute the difference between the neurons weights and the input\n",
    "        self.delta_wgt =  tf.subtract(\n",
    "                              tf.expand_dims(\n",
    "                                  self.sample, # [dim] -> [1, dim]\n",
    "                                  axis=0\n",
    "                              ),\n",
    "                              self.map_wgt, # [m*n*o, dim]\n",
    "                          )\n",
    "\n",
    "        # compute the weights update according to the learning and delta_wgt and update the weights\n",
    "        tf.compat.v1.assign_add(\n",
    "            self.map_wgt,\n",
    "            tf.multiply(\n",
    "                tf.expand_dims(\n",
    "                    self.learning, # [m*n*o] -> [m*n*o, 1]\n",
    "                    axis=-1\n",
    "                ),\n",
    "                self.delta_wgt # [m*n*o, dim]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def get_weights(self):\n",
    "        return self.map_wgt\n",
    "\n",
    "    @tf.function\n",
    "    def train(self, nbr_epochs, epsilon_i, epsilon_f, eta_i, eta_f, x_train, x_label, index_label, x_test, index_test):\n",
    "        with tf.device('/device:gpu:0'):\n",
    "            for epoch in tf.range(nbr_epochs):\n",
    "                tf.print(\"---------- Epoch\", epoch + 1, \"----------\")\n",
    "\n",
    "                # update the learning rate epsilon\n",
    "                epsilon_t =  tf.multiply(\n",
    "                                    epsilon_i,\n",
    "                                    tf.pow(\n",
    "                                        tf.math.divide(\n",
    "                                            epsilon_f,\n",
    "                                            epsilon_i\n",
    "                                        ),\n",
    "                                        tf.cast(\n",
    "                                            tf.math.divide(\n",
    "                                                epoch,\n",
    "                                                nbr_epochs - 1\n",
    "                                            ),\n",
    "                                            dtype=tf.float32\n",
    "                                        )\n",
    "                                    )\n",
    "                                )\n",
    "\n",
    "                # update the gaussian neighborhood witdh eta\n",
    "                eta_t =  tf.multiply(\n",
    "                                  eta_i,\n",
    "                                  tf.pow(\n",
    "                                      tf.math.divide(\n",
    "                                          eta_f,\n",
    "                                          eta_i\n",
    "                                      ),\n",
    "                                      tf.cast(\n",
    "                                          tf.math.divide(\n",
    "                                              epoch,\n",
    "                                              nbr_epochs - 1\n",
    "                                          ),\n",
    "                                          dtype=tf.float32\n",
    "                                      )\n",
    "                                  )\n",
    "                              )\n",
    "\n",
    "                # shuffle the training dataset\n",
    "                tf.random.shuffle(x_train)\n",
    "\n",
    "                # bmu computing and network update for each sample\n",
    "                for x_trn in x_train:\n",
    "                    sample = tf.cast(x_trn, dtype=tf.float32)\n",
    "                    self.compute_winner(sample)\n",
    "                    self.update_network(epsilon_t, eta_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "p9xYsJzJsxVs"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "#from imports import *\n",
    "\n",
    "class KSOM():\n",
    "    def __init__(self, m, n, dim):\n",
    "        self.m = m\n",
    "        self.n = n\n",
    "        self.dim = dim\n",
    "        self.map_wgt =  tf.Variable(\n",
    "                            tf.random.uniform(\n",
    "                                shape = [m*n, dim],\n",
    "                                minval = 0.0,\n",
    "                                maxval = 1.0,\n",
    "                                dtype = tf.float32,\n",
    "                                seed = 23\n",
    "                            )\n",
    "                        )\n",
    "        self.map_loc =  tf.constant(\n",
    "                            np.array(\n",
    "                                list(self.neuron_locs(m, n))\n",
    "                            )\n",
    "                        )\n",
    "\n",
    "    def neuron_locs(self, m, n):\n",
    "        # nested iterations over both dimensions to yield one by one the 2-d locations of the individual neurons in the SOM\n",
    "        for i in range(m):\n",
    "            for j in range(n):\n",
    "                yield np.array([i,j], dtype=np.float32)\n",
    "\n",
    "    def compute_winner(self, sample):\n",
    "            self.sample = sample\n",
    "\n",
    "            # compute the squared euclidean distance between the input and the neurons\n",
    "            self.squared_distance = tf.reduce_sum(\n",
    "                                        tf.square(\n",
    "                                            tf.subtract(\n",
    "                                                self.map_wgt, # [m*n, dim]\n",
    "                                                tf.expand_dims(\n",
    "                                                    self.sample, # [dim] -> [1, dim]\n",
    "                                                    axis=0\n",
    "                                                )\n",
    "                                            )\n",
    "                                        ),\n",
    "                                        axis=1\n",
    "                                    )\n",
    "\n",
    "            # find the bmu's index\n",
    "            self.bmu_idx =  tf.argmin(\n",
    "                                    input=self.squared_distance,\n",
    "                                    axis=0\n",
    "                                )\n",
    "\n",
    "            # extract the bmu's 2-d location\n",
    "            self.bmu_loc =  tf.gather(\n",
    "                                self.map_loc,\n",
    "                                self.bmu_idx\n",
    "                            )\n",
    "\n",
    "    def update_network(self, epsilon, eta):\n",
    "        # compute the squared manhattan distance between the bmu and the neurons\n",
    "        self.bmu_distance_squares = tf.reduce_sum(\n",
    "                                        tf.square(\n",
    "                                            tf.subtract(\n",
    "                                                self.map_loc, # [m*n, 2]\n",
    "                                                tf.expand_dims(\n",
    "                                                    self.bmu_loc, # [2] -> [1, 2]\n",
    "                                                    axis=0\n",
    "                                                )\n",
    "                                            )\n",
    "                                        ),\n",
    "                                        axis=1\n",
    "                                    )\n",
    "\n",
    "        # compute the neighborhood function\n",
    "        self.neighbourhood_func = tf.exp(\n",
    "                                      tf.negative(\n",
    "                                          tf.math.divide(\n",
    "                                              self.bmu_distance_squares,\n",
    "                                              tf.multiply(\n",
    "                                                  tf.square(\n",
    "                                                      eta,\n",
    "                                                  ),\n",
    "                                                  2.0\n",
    "                                              )\n",
    "                                          )\n",
    "                                      )\n",
    "                                  )\n",
    "\n",
    "        # compute the overall learning of each neuron\n",
    "        self.learning = tf.multiply(\n",
    "                            self.neighbourhood_func,\n",
    "                            epsilon\n",
    "                        )\n",
    "\n",
    "        # compute the difference between the neurons weights and the input\n",
    "        self.delta_wgt =  tf.subtract(\n",
    "                              tf.expand_dims(\n",
    "                                  self.sample, # [dim] -> [1, dim]\n",
    "                                  axis=0\n",
    "                              ),\n",
    "                              self.map_wgt, # [m*n, dim]\n",
    "                          )\n",
    "\n",
    "        # compute the weights update according to the learning and delta_wgt and update the weights\n",
    "        tf.compat.v1.assign_add(\n",
    "            self.map_wgt,\n",
    "            tf.multiply(\n",
    "                tf.expand_dims(\n",
    "                    self.learning, # [m*n] -> [m*n, 1]\n",
    "                    axis=-1\n",
    "                ),\n",
    "                self.delta_wgt # [m*n, dim]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def get_weights(self):\n",
    "        return self.map_wgt\n",
    "\n",
    "    @tf.function\n",
    "    def train(self, nbr_epochs, epsilon_i, epsilon_f, eta_i, eta_f, x_train, x_label, index_label, x_test, index_test):\n",
    "        with tf.device('/device:gpu:0'):\n",
    "            for epoch in tf.range(nbr_epochs):\n",
    "                tf.print(\"---------- Epoch\", epoch + 1, \"----------\")\n",
    "\n",
    "                # update the learning rate epsilon\n",
    "                epsilon_t =  tf.multiply(\n",
    "                                    epsilon_i,\n",
    "                                    tf.pow(\n",
    "                                        tf.math.divide(\n",
    "                                            epsilon_f,\n",
    "                                            epsilon_i\n",
    "                                        ),\n",
    "                                        tf.cast(\n",
    "                                            tf.math.divide(\n",
    "                                                epoch,\n",
    "                                                nbr_epochs - 1\n",
    "                                            ),\n",
    "                                            dtype=tf.float32\n",
    "                                        )\n",
    "                                    )\n",
    "                                )\n",
    "\n",
    "                # update the gaussian neighborhood witdh eta\n",
    "                eta_t =  tf.multiply(\n",
    "                                  eta_i,\n",
    "                                  tf.pow(\n",
    "                                      tf.math.divide(\n",
    "                                          eta_f,\n",
    "                                          eta_i\n",
    "                                      ),\n",
    "                                      tf.cast(\n",
    "                                          tf.math.divide(\n",
    "                                              epoch,\n",
    "                                              nbr_epochs - 1\n",
    "                                          ),\n",
    "                                          dtype=tf.float32\n",
    "                                      )\n",
    "                                  )\n",
    "                              )\n",
    "\n",
    "                # shuffle the training dataset\n",
    "                tf.random.shuffle(x_train)\n",
    "\n",
    "                # bmu computing and network update for each sample\n",
    "                for x_trn in x_train:\n",
    "                    sample = tf.cast(x_trn, dtype=tf.float32)\n",
    "                    self.compute_winner(sample)\n",
    "                    self.update_network(epsilon_t, eta_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YUp4My6JvezM"
   },
   "source": [
    "### From label.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "en6uoQRUveCP"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "#from imports import *\n",
    "from test import *\n",
    "\n",
    "def labeling(label_data, class_nbr, weights, x_label, index_label, sigma):\n",
    "    dist_sum = np.zeros((len(weights), class_nbr))\n",
    "    nbr_digits = np.zeros((class_nbr,))\n",
    "\n",
    "    # accumulate the normalized gaussian distance for the labeling dataset\n",
    "    for (x, y) in zip(x_label, index_label):\n",
    "        nbr_digits[y] += 1\n",
    "        dist_neuron = np.exp(-np.linalg.norm(x - weights, axis=1)/sigma)\n",
    "        dist_bmu = np.max(dist_neuron)\n",
    "        for i, distn in enumerate(dist_neuron):\n",
    "            dist_sum[i][y] += distn/dist_bmu\n",
    "\n",
    "    # normalize the activities on the number of samples per class\n",
    "    for i, dists in enumerate(dist_sum):\n",
    "        dist_sum[i] = dists/nbr_digits\n",
    "\n",
    "    # assign the neurons labels\n",
    "    neuron_label = np.argmax(dist_sum, axis=1)\n",
    "    print(\"Neurons labels = \")\n",
    "    print(neuron_label)\n",
    "\n",
    "    return neuron_label\n",
    "\n",
    "def unison_shuffle(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "\n",
    "def run_labeling(weights, label_data, x_tr, index_tr, x_ts, index_ts):\n",
    "    class_nbr = 10\n",
    "    sigma_kernel = 1.0\n",
    "    for i in range(10):\n",
    "        x_tr, index_tr = unison_shuffle(x_tr, index_tr)\n",
    "        x_lb = np.copy(x_tr[:label_data,:])\n",
    "        index_lb = np.copy(index_tr[:label_data])\n",
    "\n",
    "        # label the network\n",
    "        neuron_label = labeling(label_data, class_nbr, weights, x_lb, index_lb, sigma_kernel)\n",
    "\n",
    "        # test the network\n",
    "        accuracy = test(class_nbr, weights, x_ts, index_ts, neuron_label, sigma_kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JX3nufEBt-xM"
   },
   "source": [
    "### From test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "asaKcZRStV4v"
   },
   "outputs": [],
   "source": [
    "# from imports import *\n",
    "\n",
    "def test(class_nbr, weights, x_test, index_test, neuron_label, sigma):\n",
    "    neuron_index = np.zeros((len(x_test),), dtype=int)\n",
    "\n",
    "    # calculate the BMUs for the test dataset\n",
    "    for i, x in enumerate(x_test):\n",
    "        dist_neuron = np.linalg.norm(x - weights, axis=1)\n",
    "        neuron_index[i] = np.argmin(dist_neuron)\n",
    "\n",
    "    # compare the BMUs labels and the samples labels\n",
    "    accuracy = 0\n",
    "    for p, t in zip(neuron_index, index_test):\n",
    "        if neuron_label[p] == t:\n",
    "            accuracy += 1\n",
    "    accuracy = (float(accuracy)/len(x_test))*100\n",
    "    print(\"SOM test accuracy = %.2f\\n\" % accuracy)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E5SLZJdjz9Xi"
   },
   "source": [
    "# Adjustments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WSHRg9DtuibD"
   },
   "source": [
    "## From main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BOHsSjPUAvmU"
   },
   "source": [
    "#### Later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J5VwZcytoBuW"
   },
   "source": [
    "##### Mapa 20 por 20 = 400 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# ####################################################################################################\n",
    "# GPU-based Self-Organizing-Map by Lyes Khacef.\n",
    "# Reference: L. Khacef, V. Gripon, and B. Miramond, “GPU-based self-organizing-maps\n",
    "# for post-labeled few-shot unsupervised learning”, in International Conference On\n",
    "# Neural Information Processing (ICONIP), 2020.\n",
    "# ####################################################################################################\n",
    "\n",
    "# hyper-parameters\n",
    "train_data = 60000\n",
    "label_data = 600\n",
    "test_data = 10000\n",
    "input_dim = 400 #784\n",
    "map_wth = 20 # 10\n",
    "map_hgt = 20 # 10\n",
    "map_dpt = 8\n",
    "class_nbr = 10\n",
    "nbr_epochs = 20 # 20\n",
    "eps_i_list = [1.0]\n",
    "eps_f_list = [0.01]\n",
    "eta_i_list = [10.0]\n",
    "eta_f_list = [0.01]\n",
    "sigma_kernel = 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: \n"
     ]
    }
   ],
   "source": [
    "# GPU name\n",
    "device_name = tf.test.gpu_device_name()\n",
    "#if device_name != '/device:GPU:0':\n",
    "#    raise SystemError(\"GPU device not found!\")\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nzCPcPWZuBfK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hyper-parameters:   # eps_i = 1.000000   # eps_f = 0.010000   # eta_i = 10.000000   # eta_f = 0.010000\n",
      "WARNING:tensorflow:From d:\\progs\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\converters\\directives.py:126: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "---------- Epoch 1 ----------\n",
      "---------- Epoch 2 ----------\n",
      "---------- Epoch 3 ----------\n",
      "---------- Epoch 4 ----------\n",
      "---------- Epoch 5 ----------\n",
      "---------- Epoch 6 ----------\n",
      "---------- Epoch 7 ----------\n",
      "---------- Epoch 8 ----------\n",
      "---------- Epoch 9 ----------\n",
      "---------- Epoch 10 ----------\n",
      "---------- Epoch 11 ----------\n",
      "---------- Epoch 12 ----------\n",
      "---------- Epoch 13 ----------\n",
      "---------- Epoch 14 ----------\n",
      "---------- Epoch 15 ----------\n",
      "---------- Epoch 16 ----------\n",
      "---------- Epoch 17 ----------\n",
      "---------- Epoch 18 ----------\n",
      "---------- Epoch 19 ----------\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## So, what if theres not test data\n",
    "##\n",
    "# load dataset\n",
    "# x_train, index_train, x_label, index_label, x_test, index_test, label_data = get_dataset(train_data, label_data, test_data)\n",
    "index_train, x_label, index_label, x_test, index_test, label_data = False, False, False, False, False, False\n",
    "x_train = npdf1\n",
    "\n",
    "##\n",
    "## how the hell\n",
    "##\n",
    "# false run_som(false, false, false, eta_f):\n",
    "def run_som(eps_i, eps_f, eta_i, eta_f):\n",
    "    print(\"\\nHyper-parameters:   # eps_i = %f   # eps_f = %f   # eta_i = %f   # eta_f = %f\" % (eps_i, eps_f, eta_i, eta_f))\n",
    "    # train the network\n",
    "    som = KSOM_3D(map_wth, map_hgt, map_dpt, input_dim)\n",
    "    start_time = timeit.default_timer()\n",
    "    som.train(nbr_epochs, eps_i, eps_f, eta_i, eta_f, x_train, x_label, index_label, x_test, index_test)\n",
    "    end_time = timeit.default_timer()\n",
    "    print(\"\\nSOM training time = \", end_time - start_time)\n",
    "    weights = som.get_weights().numpy()\n",
    "\n",
    "    # save the weights\n",
    "    #np.save(\"weights/som_weights.npy\", weights)\n",
    "\n",
    "    ##\n",
    "    ## Now you no label\n",
    "    ##\n",
    "    # label the network\n",
    "    #neuron_label = labeling(label_data, class_nbr, weights, x_label, index_label, sigma_kernel)\n",
    "    neuron_label = False\n",
    "\n",
    "    ##\n",
    "    ## Now you no accuracy\n",
    "    # test the network\n",
    "    #accuracy = test(class_nbr, weights, x_test, index_test, neuron_label, sigma_kernel)\n",
    "    accuracy = False\n",
    "\n",
    "    return weights, accuracy\n",
    "\n",
    "# hyper-parameters grid search\n",
    "hyper_param_list, accuracy_list = [], []\n",
    "for eps_i in eps_i_list:\n",
    "    for eps_f in eps_f_list:\n",
    "        for eta_i in eta_i_list:\n",
    "            for eta_f in eta_f_list:\n",
    "                hyper_param_list.append([eps_i, eps_f, eta_i, eta_f])\n",
    "                weights, accuracy = run_som(eps_i, eps_f, eta_i, eta_f)\n",
    "                accuracy_list.append(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iAxHUdeg-xCG"
   },
   "outputs": [],
   "source": [
    "# GPU memory check\n",
    "gpu_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wc8YlV34BNZc"
   },
   "outputs": [],
   "source": [
    "for k in range(map_dpt):\n",
    "  # display neurons weights as mnist digits\n",
    "  som_grid = plt.figure(figsize=(20, 20)) # width, height in inches\n",
    "  for n in range(map_wth*map_hgt):\n",
    "      ##\n",
    "      ## Must make this into time series plot. Shouldnt be the thing\n",
    "      ##\n",
    "      #image = weights[n].reshape([28,28]) # x_train[num] is the 784 normalized pixel values\n",
    "      sub = som_grid.add_subplot(map_wth, map_hgt, n + 1)\n",
    "      sub.set_axis_off()\n",
    "      clr = sub.plot(weights[n][k]) # imshow(image, cmap = plt.get_cmap(\"jet\"), interpolation = \"nearest\")\n",
    "      #plt.colorbar(clr)\n",
    "  #plt.savefig(\"plots/som_weights.png\")\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mf9RW9P6n21I"
   },
   "source": [
    "##### Mapa 10 por 10 = 100 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "owpAMTdYToa3"
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# ####################################################################################################\n",
    "# GPU-based Self-Organizing-Map by Lyes Khacef.\n",
    "# Reference: L. Khacef, V. Gripon, and B. Miramond, “GPU-based self-organizing-maps\n",
    "# for post-labeled few-shot unsupervised learning”, in International Conference On\n",
    "# Neural Information Processing (ICONIP), 2020.\n",
    "# ####################################################################################################\n",
    "\n",
    "# imports\n",
    "#from imports import *\n",
    "#from gpu_check import *\n",
    "#from data_load import *\n",
    "#from tf_ksom import *\n",
    "#from label import *\n",
    "#from test import *\n",
    "\n",
    "# hyper-parameters\n",
    "train_data = 60000\n",
    "label_data = 600\n",
    "test_data = 10000\n",
    "input_dim = 400 #784\n",
    "map_wth = 10\n",
    "map_hgt = 10\n",
    "class_nbr = 10\n",
    "nbr_epochs = 40 # 20\n",
    "eps_i_list = [1.0]\n",
    "eps_f_list = [0.01]\n",
    "eta_i_list = [10.0]\n",
    "eta_f_list = [0.01]\n",
    "sigma_kernel = 1.0\n",
    "\n",
    "# GPU name\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    raise SystemError(\"GPU device not found!\")\n",
    "print('Found GPU at: {}'.format(device_name))\n",
    "\n",
    "##\n",
    "## So, what if theres not test data\n",
    "##\n",
    "# load dataset\n",
    "# x_train, index_train, x_label, index_label, x_test, index_test, label_data = get_dataset(train_data, label_data, test_data)\n",
    "index_train, x_label, index_label, x_test, index_test, label_data = False, False, False, False, False, False\n",
    "x_train = npdf1\n",
    "\n",
    "##\n",
    "## how the hell\n",
    "##\n",
    "# false run_som(false, false, false, eta_f):\n",
    "def run_som(eps_i, eps_f, eta_i, eta_f):\n",
    "    print(\"\\nHyper-parameters:   # eps_i = %f   # eps_f = %f   # eta_i = %f   # eta_f = %f\" % (eps_i, eps_f, eta_i, eta_f))\n",
    "    # train the network\n",
    "    som = KSOM(map_wth, map_hgt, input_dim)\n",
    "    start_time = timeit.default_timer()\n",
    "    som.train(nbr_epochs, eps_i, eps_f, eta_i, eta_f, x_train, x_label, index_label, x_test, index_test)\n",
    "    end_time = timeit.default_timer()\n",
    "    print(\"\\nSOM training time = \", end_time - start_time)\n",
    "    weights = som.get_weights().numpy()\n",
    "\n",
    "    # save the weights\n",
    "    #np.save(\"weights/som_weights.npy\", weights)\n",
    "\n",
    "    ##\n",
    "    ## Now you no label\n",
    "    ##\n",
    "    # label the network\n",
    "    #neuron_label = labeling(label_data, class_nbr, weights, x_label, index_label, sigma_kernel)\n",
    "    neuron_label = False\n",
    "\n",
    "    ##\n",
    "    ## Now you no accuracy\n",
    "    # test the network\n",
    "    #accuracy = test(class_nbr, weights, x_test, index_test, neuron_label, sigma_kernel)\n",
    "    accuracy = False\n",
    "\n",
    "    return weights, accuracy\n",
    "\n",
    "# hyper-parameters grid search\n",
    "hyper_param_list, accuracy_list = [], []\n",
    "for eps_i in eps_i_list:\n",
    "    for eps_f in eps_f_list:\n",
    "        for eta_i in eta_i_list:\n",
    "            for eta_f in eta_f_list:\n",
    "                hyper_param_list.append([eps_i, eps_f, eta_i, eta_f])\n",
    "                weights, accuracy = run_som(eps_i, eps_f, eta_i, eta_f)\n",
    "                accuracy_list.append(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zn7V0R8xToa7"
   },
   "outputs": [],
   "source": [
    "## hyper parameters below\n",
    "## label list below\n",
    "\n",
    "# GPU memory check\n",
    "gpu_report()\n",
    "\n",
    "# display neurons weights as mnist digits\n",
    "som_grid = plt.figure(figsize=(200, 200)) # width, height in inches\n",
    "for n in range(map_wth*map_hgt):\n",
    "    ##\n",
    "    ## Must make this into time series plot. Shouldnt be the thing\n",
    "    ##\n",
    "    #image = weights[n].reshape([28,28]) # x_train[num] is the 784 normalized pixel values\n",
    "    sub = som_grid.add_subplot(map_wth, map_hgt, n + 1)\n",
    "    sub.set_axis_off()\n",
    "    clr = sub.plot(weights[n]) # imshow(image, cmap = plt.get_cmap(\"jet\"), interpolation = \"nearest\")\n",
    "    #plt.colorbar(clr)\n",
    "#plt.savefig(\"plots/som_weights.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lNJswyuzoctU"
   },
   "source": [
    "##### Mapa 5 por 5 = 25 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r2Ewk17JTt-q"
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# ####################################################################################################\n",
    "# GPU-based Self-Organizing-Map by Lyes Khacef.\n",
    "# Reference: L. Khacef, V. Gripon, and B. Miramond, “GPU-based self-organizing-maps\n",
    "# for post-labeled few-shot unsupervised learning”, in International Conference On\n",
    "# Neural Information Processing (ICONIP), 2020.\n",
    "# ####################################################################################################\n",
    "\n",
    "# imports\n",
    "#from imports import *\n",
    "#from gpu_check import *\n",
    "#from data_load import *\n",
    "#from tf_ksom import *\n",
    "#from label import *\n",
    "#from test import *\n",
    "\n",
    "# hyper-parameters\n",
    "train_data = 60000\n",
    "label_data = 600\n",
    "test_data = 10000\n",
    "input_dim = 400 #784\n",
    "map_wth = 5\n",
    "map_hgt = 5\n",
    "class_nbr = 10\n",
    "nbr_epochs = 40 # 20\n",
    "eps_i_list = [1.0]\n",
    "eps_f_list = [0.01]\n",
    "eta_i_list = [10.0]\n",
    "eta_f_list = [0.01]\n",
    "sigma_kernel = 1.0\n",
    "\n",
    "# GPU name\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    raise SystemError(\"GPU device not found!\")\n",
    "print('Found GPU at: {}'.format(device_name))\n",
    "\n",
    "##\n",
    "## So, what if theres not test data\n",
    "##\n",
    "# load dataset\n",
    "# x_train, index_train, x_label, index_label, x_test, index_test, label_data = get_dataset(train_data, label_data, test_data)\n",
    "index_train, x_label, index_label, x_test, index_test, label_data = False, False, False, False, False, False\n",
    "x_train = npdf1\n",
    "\n",
    "##\n",
    "## how the hell\n",
    "##\n",
    "# false run_som(false, false, false, eta_f):\n",
    "def run_som(eps_i, eps_f, eta_i, eta_f):\n",
    "    print(\"\\nHyper-parameters:   # eps_i = %f   # eps_f = %f   # eta_i = %f   # eta_f = %f\" % (eps_i, eps_f, eta_i, eta_f))\n",
    "    # train the network\n",
    "    som = KSOM(map_wth, map_hgt, input_dim)\n",
    "    start_time = timeit.default_timer()\n",
    "    som.train(nbr_epochs, eps_i, eps_f, eta_i, eta_f, x_train, x_label, index_label, x_test, index_test)\n",
    "    end_time = timeit.default_timer()\n",
    "    print(\"\\nSOM training time = \", end_time - start_time)\n",
    "    weights = som.get_weights().numpy()\n",
    "\n",
    "    # save the weights\n",
    "    #np.save(\"weights/som_weights.npy\", weights)\n",
    "\n",
    "    ##\n",
    "    ## Now you no label\n",
    "    ##\n",
    "    # label the network\n",
    "    #neuron_label = labeling(label_data, class_nbr, weights, x_label, index_label, sigma_kernel)\n",
    "    neuron_label = False\n",
    "\n",
    "    ##\n",
    "    ## Now you no accuracy\n",
    "    # test the network\n",
    "    #accuracy = test(class_nbr, weights, x_test, index_test, neuron_label, sigma_kernel)\n",
    "    accuracy = False\n",
    "\n",
    "    return weights, accuracy\n",
    "\n",
    "# hyper-parameters grid search\n",
    "hyper_param_list, accuracy_list = [], []\n",
    "for eps_i in eps_i_list:\n",
    "    for eps_f in eps_f_list:\n",
    "        for eta_i in eta_i_list:\n",
    "            for eta_f in eta_f_list:\n",
    "                hyper_param_list.append([eps_i, eps_f, eta_i, eta_f])\n",
    "                weights, accuracy = run_som(eps_i, eps_f, eta_i, eta_f)\n",
    "                accuracy_list.append(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B2PjlImfTt-r"
   },
   "outputs": [],
   "source": [
    "## hyper parameters below\n",
    "## label list below\n",
    "\n",
    "# GPU memory check\n",
    "gpu_report()\n",
    "\n",
    "# display neurons weights as mnist digits\n",
    "som_grid = plt.figure(figsize=(200, 200)) # width, height in inches\n",
    "for n in range(map_wth*map_hgt):\n",
    "    ##\n",
    "    ## Must make this into time series plot. Shouldnt be the thing\n",
    "    ##\n",
    "    #image = weights[n].reshape([28,28]) # x_train[num] is the 784 normalized pixel values\n",
    "    sub = som_grid.add_subplot(map_wth, map_hgt, n + 1)\n",
    "    sub.set_axis_off()\n",
    "    clr = sub.plot(weights[n]) # imshow(image, cmap = plt.get_cmap(\"jet\"), interpolation = \"nearest\")\n",
    "    #plt.colorbar(clr)\n",
    "#plt.savefig(\"plots/som_weights.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UwqctnJ-p4Rs"
   },
   "source": [
    "##### Mapa 4 por 4 = 16 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E313I_kokU2C"
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# ####################################################################################################\n",
    "# GPU-based Self-Organizing-Map by Lyes Khacef.\n",
    "# Reference: L. Khacef, V. Gripon, and B. Miramond, “GPU-based self-organizing-maps\n",
    "# for post-labeled few-shot unsupervised learning”, in International Conference On\n",
    "# Neural Information Processing (ICONIP), 2020.\n",
    "# ####################################################################################################\n",
    "\n",
    "# imports\n",
    "#from imports import *\n",
    "#from gpu_check import *\n",
    "#from data_load import *\n",
    "#from tf_ksom import *\n",
    "#from label import *\n",
    "#from test import *\n",
    "\n",
    "# hyper-parameters\n",
    "train_data = 60000\n",
    "label_data = 600\n",
    "test_data = 10000\n",
    "input_dim = 400 #784\n",
    "map_wth = 4\n",
    "map_hgt = 4\n",
    "class_nbr = 10\n",
    "nbr_epochs = 40 # 20\n",
    "eps_i_list = [1.0]\n",
    "eps_f_list = [0.01]\n",
    "eta_i_list = [10.0]\n",
    "eta_f_list = [0.01]\n",
    "sigma_kernel = 1.0\n",
    "\n",
    "# GPU name\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    raise SystemError(\"GPU device not found!\")\n",
    "print('Found GPU at: {}'.format(device_name))\n",
    "\n",
    "##\n",
    "## So, what if theres not test data\n",
    "##\n",
    "# load dataset\n",
    "# x_train, index_train, x_label, index_label, x_test, index_test, label_data = get_dataset(train_data, label_data, test_data)\n",
    "index_train, x_label, index_label, x_test, index_test, label_data = False, False, False, False, False, False\n",
    "x_train = npdf1\n",
    "\n",
    "##\n",
    "## how the hell\n",
    "##\n",
    "# false run_som(false, false, false, eta_f):\n",
    "def run_som(eps_i, eps_f, eta_i, eta_f):\n",
    "    print(\"\\nHyper-parameters:   # eps_i = %f   # eps_f = %f   # eta_i = %f   # eta_f = %f\" % (eps_i, eps_f, eta_i, eta_f))\n",
    "    # train the network\n",
    "    som = KSOM(map_wth, map_hgt, input_dim)\n",
    "    start_time = timeit.default_timer()\n",
    "    som.train(nbr_epochs, eps_i, eps_f, eta_i, eta_f, x_train, x_label, index_label, x_test, index_test)\n",
    "    end_time = timeit.default_timer()\n",
    "    print(\"\\nSOM training time = \", end_time - start_time)\n",
    "    weights = som.get_weights().numpy()\n",
    "\n",
    "    # save the weights\n",
    "    #np.save(\"weights/som_weights.npy\", weights)\n",
    "\n",
    "    ##\n",
    "    ## Now you no label\n",
    "    ##\n",
    "    # label the network\n",
    "    #neuron_label = labeling(label_data, class_nbr, weights, x_label, index_label, sigma_kernel)\n",
    "    neuron_label = False\n",
    "\n",
    "    ##\n",
    "    ## Now you no accuracy\n",
    "    # test the network\n",
    "    #accuracy = test(class_nbr, weights, x_test, index_test, neuron_label, sigma_kernel)\n",
    "    accuracy = False\n",
    "\n",
    "    return weights, accuracy\n",
    "\n",
    "# hyper-parameters grid search\n",
    "hyper_param_list, accuracy_list = [], []\n",
    "for eps_i in eps_i_list:\n",
    "    for eps_f in eps_f_list:\n",
    "        for eta_i in eta_i_list:\n",
    "            for eta_f in eta_f_list:\n",
    "                hyper_param_list.append([eps_i, eps_f, eta_i, eta_f])\n",
    "                weights, accuracy = run_som(eps_i, eps_f, eta_i, eta_f)\n",
    "                accuracy_list.append(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jepFqSPQkU2J"
   },
   "outputs": [],
   "source": [
    "## hyper parameters below\n",
    "## label list below\n",
    "\n",
    "# GPU memory check\n",
    "gpu_report()\n",
    "\n",
    "# display neurons weights as mnist digits\n",
    "som_grid = plt.figure(figsize=(200, 200)) # width, height in inches\n",
    "for n in range(map_wth*map_hgt):\n",
    "    ##\n",
    "    ## Must make this into time series plot. Shouldnt be the thing\n",
    "    ##\n",
    "    #image = weights[n].reshape([28,28]) # x_train[num] is the 784 normalized pixel values\n",
    "    sub = som_grid.add_subplot(map_wth, map_hgt, n + 1)\n",
    "    sub.set_axis_off()\n",
    "    clr = sub.plot(weights[n]) # imshow(image, cmap = plt.get_cmap(\"jet\"), interpolation = \"nearest\")\n",
    "    #plt.colorbar(clr)\n",
    "#plt.savefig(\"plots/som_weights.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bA4o_Y2wqmfT"
   },
   "source": [
    "#### Mapa 3 por 3 = 9 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qt2SzgvIdeIK"
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# ####################################################################################################\n",
    "# GPU-based Self-Organizing-Map by Lyes Khacef.\n",
    "# Reference: L. Khacef, V. Gripon, and B. Miramond, “GPU-based self-organizing-maps\n",
    "# for post-labeled few-shot unsupervised learning”, in International Conference On\n",
    "# Neural Information Processing (ICONIP), 2020.\n",
    "# ####################################################################################################\n",
    "\n",
    "# imports\n",
    "#from imports import *\n",
    "#from gpu_check import *\n",
    "#from data_load import *\n",
    "#from tf_ksom import *\n",
    "#from label import *\n",
    "#from test import *\n",
    "\n",
    "# hyper-parameters\n",
    "train_data = 60000\n",
    "label_data = 600\n",
    "test_data = 10000\n",
    "input_dim = 400 #784\n",
    "map_wth = 3\n",
    "map_hgt = 3\n",
    "class_nbr = 10\n",
    "nbr_epochs = 40 # 20\n",
    "eps_i_list = [1.0]\n",
    "eps_f_list = [0.01]\n",
    "eta_i_list = [10.0]\n",
    "eta_f_list = [0.01]\n",
    "sigma_kernel = 1.0\n",
    "\n",
    "# GPU name\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    raise SystemError(\"GPU device not found!\")\n",
    "print('Found GPU at: {}'.format(device_name))\n",
    "\n",
    "##\n",
    "## So, what if theres not test data\n",
    "##\n",
    "# load dataset\n",
    "# x_train, index_train, x_label, index_label, x_test, index_test, label_data = get_dataset(train_data, label_data, test_data)\n",
    "index_train, x_label, index_label, x_test, index_test, label_data = False, False, False, False, False, False\n",
    "x_train = npdf1\n",
    "\n",
    "##\n",
    "## how the hell\n",
    "##\n",
    "# false run_som(false, false, false, eta_f):\n",
    "def run_som(eps_i, eps_f, eta_i, eta_f):\n",
    "    print(\"\\nHyper-parameters:   # eps_i = %f   # eps_f = %f   # eta_i = %f   # eta_f = %f\" % (eps_i, eps_f, eta_i, eta_f))\n",
    "    # train the network\n",
    "    som = KSOM(map_wth, map_hgt, input_dim)\n",
    "    start_time = timeit.default_timer()\n",
    "    som.train(nbr_epochs, eps_i, eps_f, eta_i, eta_f, x_train, x_label, index_label, x_test, index_test)\n",
    "    end_time = timeit.default_timer()\n",
    "    print(\"\\nSOM training time = \", end_time - start_time)\n",
    "    weights = som.get_weights().numpy()\n",
    "\n",
    "    # save the weights\n",
    "    #np.save(\"weights/som_weights.npy\", weights)\n",
    "\n",
    "    ##\n",
    "    ## Now you no label\n",
    "    ##\n",
    "    # label the network\n",
    "    #neuron_label = labeling(label_data, class_nbr, weights, x_label, index_label, sigma_kernel)\n",
    "    neuron_label = False\n",
    "\n",
    "    ##\n",
    "    ## Now you no accuracy\n",
    "    # test the network\n",
    "    #accuracy = test(class_nbr, weights, x_test, index_test, neuron_label, sigma_kernel)\n",
    "    accuracy = False\n",
    "\n",
    "    return weights, accuracy\n",
    "\n",
    "# hyper-parameters grid search\n",
    "hyper_param_list, accuracy_list = [], []\n",
    "for eps_i in eps_i_list:\n",
    "    for eps_f in eps_f_list:\n",
    "        for eta_i in eta_i_list:\n",
    "            for eta_f in eta_f_list:\n",
    "                hyper_param_list.append([eps_i, eps_f, eta_i, eta_f])\n",
    "                weights, accuracy = run_som(eps_i, eps_f, eta_i, eta_f)\n",
    "                accuracy_list.append(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z2cLey3zTNNO"
   },
   "outputs": [],
   "source": [
    "# display neurons weights as time series\n",
    "som_grid = plt.figure(figsize=(10, 10)) # width, height in inches\n",
    "for i in range(map_wth):\n",
    "  for j in range(map_hgt):\n",
    "    sub = som_grid.add_subplot(map_wth*map_dpt, map_hgt, 4*k+2*i+j+1)\n",
    "    for k in range(map_dpt):\n",
    "        #image = weights[n].reshape([28,28]) # x_train[num] is the 784 normalized pixel values\n",
    "        sub.set_axis_off()\n",
    "        clr = sub.plot(range(400),weights[4*k+2*i+j],k)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A9GuYC_IUpFe"
   },
   "outputs": [],
   "source": [
    "print('i:'+str(i)+' and j: '+str(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z2rQ1dzOdeIM"
   },
   "outputs": [],
   "source": [
    "## hyper parameters below\n",
    "## label list below\n",
    "\n",
    "# GPU memory check\n",
    "gpu_report()\n",
    "\n",
    "# display neurons weights as mnist digits\n",
    "som_grid = plt.figure(figsize=(200, 200)) # width, height in inches\n",
    "for n in range(map_wth*map_hgt*map_dpt):\n",
    "    ##\n",
    "    ## Must make this into time series plot. Shouldnt be the thing\n",
    "    ##\n",
    "    #image = weights[n].reshape([28,28]) # x_train[num] is the 784 normalized pixel values\n",
    "    sub = som_grid.add_subplot(map_wth, map_hgt, n + 1)\n",
    "    sub.set_axis_off()\n",
    "    clr = sub.plot(weights[n]) # imshow(image, cmap = plt.get_cmap(\"jet\"), interpolation = \"nearest\")\n",
    "    #plt.colorbar(clr)\n",
    "#plt.savefig(\"plots/som_weights.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-9TGxfebS4MX"
   },
   "source": [
    "#### Mapa 3 por 3 por 3 = 27 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ARvROyA6S66O"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lvaCQOBoS7VY"
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# ####################################################################################################\n",
    "# GPU-based Self-Organizing-Map by Lyes Khacef.\n",
    "# Reference: L. Khacef, V. Gripon, and B. Miramond, “GPU-based self-organizing-maps\n",
    "# for post-labeled few-shot unsupervised learning”, in International Conference On\n",
    "# Neural Information Processing (ICONIP), 2020.\n",
    "# ####################################################################################################\n",
    "\n",
    "# imports\n",
    "#from imports import *\n",
    "#from gpu_check import *\n",
    "#from data_load import *\n",
    "#from tf_ksom import *\n",
    "#from label import *\n",
    "#from test import *\n",
    "\n",
    "# hyper-parameters\n",
    "train_data = 60000\n",
    "label_data = 600\n",
    "test_data = 10000\n",
    "input_dim = 400 #784\n",
    "map_wth = 3\n",
    "map_hgt = 3\n",
    "map_dpt = 3\n",
    "class_nbr = 10\n",
    "nbr_epochs = 40 # 20\n",
    "eps_i_list = [1.0]\n",
    "eps_f_list = [0.01]\n",
    "eta_i_list = [10.0]\n",
    "eta_f_list = [0.01]\n",
    "sigma_kernel = 1.0\n",
    "\n",
    "# GPU name\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    raise SystemError(\"GPU device not found!\")\n",
    "print('Found GPU at: {}'.format(device_name))\n",
    "\n",
    "##\n",
    "## So, what if theres not test data\n",
    "##\n",
    "# load dataset\n",
    "# x_train, index_train, x_label, index_label, x_test, index_test, label_data = get_dataset(train_data, label_data, test_data)\n",
    "index_train, x_label, index_label, x_test, index_test, label_data = False, False, False, False, False, False\n",
    "x_train = npdf1\n",
    "\n",
    "##\n",
    "## how the hell\n",
    "##\n",
    "# false run_som(false, false, false, eta_f):\n",
    "def run_som(eps_i, eps_f, eta_i, eta_f):\n",
    "    print(\"\\nHyper-parameters:   # eps_i = %f   # eps_f = %f   # eta_i = %f   # eta_f = %f\" % (eps_i, eps_f, eta_i, eta_f))\n",
    "    # train the network\n",
    "    som = KSOM_3D(map_wth, map_hgt, map_dpt, input_dim)\n",
    "    start_time = timeit.default_timer()\n",
    "    som.train(nbr_epochs, eps_i, eps_f, eta_i, eta_f, x_train, x_label, index_label, x_test, index_test)\n",
    "    end_time = timeit.default_timer()\n",
    "    print(\"\\nSOM training time = \", end_time - start_time)\n",
    "    weights = som.get_weights().numpy()\n",
    "\n",
    "    # save the weights\n",
    "    #np.save(\"weights/som_weights.npy\", weights)\n",
    "\n",
    "    ##\n",
    "    ## Now you no label\n",
    "    ##\n",
    "    # label the network\n",
    "    #neuron_label = labeling(label_data, class_nbr, weights, x_label, index_label, sigma_kernel)\n",
    "    neuron_label = False\n",
    "\n",
    "    ##\n",
    "    ## Now you no accuracy\n",
    "    # test the network\n",
    "    #accuracy = test(class_nbr, weights, x_test, index_test, neuron_label, sigma_kernel)\n",
    "    accuracy = False\n",
    "\n",
    "    return weights, accuracy\n",
    "\n",
    "# hyper-parameters grid search\n",
    "hyper_param_list, accuracy_list = [], []\n",
    "for eps_i in eps_i_list:\n",
    "    for eps_f in eps_f_list:\n",
    "        for eta_i in eta_i_list:\n",
    "            for eta_f in eta_f_list:\n",
    "                hyper_param_list.append([eps_i, eps_f, eta_i, eta_f])\n",
    "                weights, accuracy = run_som(eps_i, eps_f, eta_i, eta_f)\n",
    "                accuracy_list.append(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cKtk3t3qS7VZ"
   },
   "outputs": [],
   "source": [
    "# display neurons weights as time series\n",
    "som_grid = plt.figure(figsize=(10, 10)) # width, height in inches\n",
    "for i in range(map_wth):\n",
    "  for j in range(map_hgt):\n",
    "    for k in range(map_dpt):\n",
    "      sub = som_grid.add_subplot(map_wth, map_hgt, 3*j+i+1)\n",
    "      #image = weights[n].reshape([28,28]) # x_train[num] is the 784 normalized pixel values\n",
    "      sub.set_axis_off()\n",
    "      clr = sub.plot(range(400),weights[9*k+3*j+i],9*k+3*j+i+1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e9J1cgzOrNqX"
   },
   "source": [
    "##### Mapa 2 por 3 = 6 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GU2ARENAd7if"
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# ####################################################################################################\n",
    "# GPU-based Self-Organizing-Map by Lyes Khacef.\n",
    "# Reference: L. Khacef, V. Gripon, and B. Miramond, “GPU-based self-organizing-maps\n",
    "# for post-labeled few-shot unsupervised learning”, in International Conference On\n",
    "# Neural Information Processing (ICONIP), 2020.\n",
    "# ####################################################################################################\n",
    "\n",
    "# imports\n",
    "#from imports import *\n",
    "#from gpu_check import *\n",
    "#from data_load import *\n",
    "#from tf_ksom import *\n",
    "#from label import *\n",
    "#from test import *\n",
    "\n",
    "# hyper-parameters\n",
    "train_data = 60000\n",
    "label_data = 600\n",
    "test_data = 10000\n",
    "input_dim = 400 #784\n",
    "map_wth = 2\n",
    "map_hgt = 3\n",
    "class_nbr = 10\n",
    "nbr_epochs = 40 # 20\n",
    "eps_i_list = [1.0]\n",
    "eps_f_list = [0.01]\n",
    "eta_i_list = [10.0]\n",
    "eta_f_list = [0.01]\n",
    "sigma_kernel = 1.0\n",
    "\n",
    "# GPU name\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    raise SystemError(\"GPU device not found!\")\n",
    "print('Found GPU at: {}'.format(device_name))\n",
    "\n",
    "##\n",
    "## So, what if theres not test data\n",
    "##\n",
    "# load dataset\n",
    "# x_train, index_train, x_label, index_label, x_test, index_test, label_data = get_dataset(train_data, label_data, test_data)\n",
    "index_train, x_label, index_label, x_test, index_test, label_data = False, False, False, False, False, False\n",
    "x_train = npdf1\n",
    "\n",
    "##\n",
    "## how the hell\n",
    "##\n",
    "# false run_som(false, false, false, eta_f):\n",
    "def run_som(eps_i, eps_f, eta_i, eta_f):\n",
    "    print(\"\\nHyper-parameters:   # eps_i = %f   # eps_f = %f   # eta_i = %f   # eta_f = %f\" % (eps_i, eps_f, eta_i, eta_f))\n",
    "    # train the network\n",
    "    som = KSOM(map_wth, map_hgt, input_dim)\n",
    "    start_time = timeit.default_timer()\n",
    "    som.train(nbr_epochs, eps_i, eps_f, eta_i, eta_f, x_train, x_label, index_label, x_test, index_test)\n",
    "    end_time = timeit.default_timer()\n",
    "    print(\"\\nSOM training time = \", end_time - start_time)\n",
    "    weights = som.get_weights().numpy()\n",
    "\n",
    "    # save the weights\n",
    "    #np.save(\"weights/som_weights.npy\", weights)\n",
    "\n",
    "    ##\n",
    "    ## Now you no label\n",
    "    ##\n",
    "    # label the network\n",
    "    #neuron_label = labeling(label_data, class_nbr, weights, x_label, index_label, sigma_kernel)\n",
    "    neuron_label = False\n",
    "\n",
    "    ##\n",
    "    ## Now you no accuracy\n",
    "    # test the network\n",
    "    #accuracy = test(class_nbr, weights, x_test, index_test, neuron_label, sigma_kernel)\n",
    "    accuracy = False\n",
    "\n",
    "    return weights, accuracy\n",
    "\n",
    "# hyper-parameters grid search\n",
    "hyper_param_list, accuracy_list = [], []\n",
    "for eps_i in eps_i_list:\n",
    "    for eps_f in eps_f_list:\n",
    "        for eta_i in eta_i_list:\n",
    "            for eta_f in eta_f_list:\n",
    "                hyper_param_list.append([eps_i, eps_f, eta_i, eta_f])\n",
    "                weights, accuracy = run_som(eps_i, eps_f, eta_i, eta_f)\n",
    "                accuracy_list.append(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IZfxx2ped7ih"
   },
   "outputs": [],
   "source": [
    "## hyper parameters below\n",
    "## label list below\n",
    "\n",
    "# GPU memory check\n",
    "gpu_report()\n",
    "\n",
    "# display neurons weights as mnist digits\n",
    "som_grid = plt.figure(figsize=(200, 200)) # width, height in inches\n",
    "for n in range(map_wth*map_hgt):\n",
    "    ##\n",
    "    ## Must make this into time series plot. Shouldnt be the thing\n",
    "    ##\n",
    "    #image = weights[n].reshape([28,28]) # x_train[num] is the 784 normalized pixel values\n",
    "    sub = som_grid.add_subplot(map_wth, map_hgt, n + 1)\n",
    "    sub.set_axis_off()\n",
    "    clr = sub.plot(weights[n]) # imshow(image, cmap = plt.get_cmap(\"jet\"), interpolation = \"nearest\")\n",
    "    #plt.colorbar(clr)\n",
    "#plt.savefig(\"plots/som_weights.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LuhmAyOyriAz"
   },
   "source": [
    "#### Mapa 2 por 2 = 4 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JrW4r5_wd8Om"
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# ####################################################################################################\n",
    "# GPU-based Self-Organizing-Map by Lyes Khacef.\n",
    "# Reference: L. Khacef, V. Gripon, and B. Miramond, “GPU-based self-organizing-maps\n",
    "# for post-labeled few-shot unsupervised learning”, in International Conference On\n",
    "# Neural Information Processing (ICONIP), 2020.\n",
    "# ####################################################################################################\n",
    "\n",
    "# imports\n",
    "#from imports import *\n",
    "#from gpu_check import *\n",
    "#from data_load import *\n",
    "#from tf_ksom import *\n",
    "#from label import *\n",
    "#from test import *\n",
    "\n",
    "# hyper-parameters\n",
    "train_data = 60000\n",
    "label_data = 600\n",
    "test_data = 10000\n",
    "input_dim = 400 #784\n",
    "map_wth = 2\n",
    "map_hgt = 2\n",
    "class_nbr = 10\n",
    "nbr_epochs = 40 # 20\n",
    "eps_i_list = [1.0]\n",
    "eps_f_list = [0.01]\n",
    "eta_i_list = [10.0]\n",
    "eta_f_list = [0.01]\n",
    "sigma_kernel = 1.0\n",
    "\n",
    "# GPU name\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    raise SystemError(\"GPU device not found!\")\n",
    "print('Found GPU at: {}'.format(device_name))\n",
    "\n",
    "##\n",
    "## So, what if theres not test data\n",
    "##\n",
    "# load dataset\n",
    "# x_train, index_train, x_label, index_label, x_test, index_test, label_data = get_dataset(train_data, label_data, test_data)\n",
    "index_train, x_label, index_label, x_test, index_test, label_data = False, False, False, False, False, False\n",
    "x_train = npdf1\n",
    "\n",
    "##\n",
    "## make the ref from outside scope\n",
    "##\n",
    "som = []\n",
    "\n",
    "##\n",
    "## how the hell\n",
    "##\n",
    "# false run_som(false, false, false, eta_f):\n",
    "def run_som(eps_i, eps_f, eta_i, eta_f):\n",
    "    print(\"\\nHyper-parameters:   # eps_i = %f   # eps_f = %f   # eta_i = %f   # eta_f = %f\" % (eps_i, eps_f, eta_i, eta_f))\n",
    "    # train the network\n",
    "    som = KSOM(map_wth, map_hgt, input_dim)\n",
    "    start_time = timeit.default_timer()\n",
    "    som.train(nbr_epochs, eps_i, eps_f, eta_i, eta_f, x_train, x_label, index_label, x_test, index_test)\n",
    "    end_time = timeit.default_timer()\n",
    "    print(\"\\nSOM training time = \", end_time - start_time)\n",
    "    weights = som.get_weights().numpy()\n",
    "\n",
    "    # save the weights\n",
    "    #np.save(\"weights/som_weights.npy\", weights)\n",
    "\n",
    "    ##\n",
    "    ## Now you no label\n",
    "    ##\n",
    "    # label the network\n",
    "    #neuron_label = labeling(label_data, class_nbr, weights, x_label, index_label, sigma_kernel)\n",
    "    neuron_label = False\n",
    "\n",
    "    ##\n",
    "    ## Now you no accuracy\n",
    "    # test the network\n",
    "    #accuracy = test(class_nbr, weights, x_test, index_test, neuron_label, sigma_kernel)\n",
    "    accuracy = False\n",
    "\n",
    "    return weights, accuracy\n",
    "\n",
    "# hyper-parameters grid search\n",
    "hyper_param_list, accuracy_list = [], []\n",
    "for eps_i in eps_i_list:\n",
    "    for eps_f in eps_f_list:\n",
    "        for eta_i in eta_i_list:\n",
    "            for eta_f in eta_f_list:\n",
    "                hyper_param_list.append([eps_i, eps_f, eta_i, eta_f])\n",
    "                weights, accuracy = run_som(eps_i, eps_f, eta_i, eta_f)\n",
    "                accuracy_list.append(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Au4lmJTgd8On"
   },
   "outputs": [],
   "source": [
    "## hyper parameters below\n",
    "## label list below\n",
    "\n",
    "# GPU memory check\n",
    "gpu_report()\n",
    "\n",
    "# display neurons weights as mnist digits\n",
    "som_grid = plt.figure(figsize=(10, 10)) # width, height in inches\n",
    "for n in range(map_wth*map_hgt):\n",
    "    ##\n",
    "    ## Must make this into time series plot. Shouldnt be the thing\n",
    "    ##\n",
    "    #image = weights[n].reshape([28,28]) # x_train[num] is the 784 normalized pixel values\n",
    "    sub = som_grid.add_subplot(map_wth, map_hgt, n + 1)\n",
    "    sub.set_axis_off()\n",
    "    clr = sub.plot(weights[n]) # imshow(image, cmap = plt.get_cmap(\"jet\"), interpolation = \"nearest\")\n",
    "    #plt.colorbar(clr)\n",
    "#plt.savefig(\"plots/som_weights.png\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hWjN57oNMZnc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Izaw5vm7N6EW"
   },
   "source": [
    "## Mapa 2 por 2 por 2 = 8 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "53d3OR15MaKH"
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# ####################################################################################################\n",
    "# GPU-based Self-Organizing-Map by Lyes Khacef.\n",
    "# Reference: L. Khacef, V. Gripon, and B. Miramond, “GPU-based self-organizing-maps\n",
    "# for post-labeled few-shot unsupervised learning”, in International Conference On\n",
    "# Neural Information Processing (ICONIP), 2020.\n",
    "# ####################################################################################################\n",
    "\n",
    "# imports\n",
    "#from imports import *\n",
    "#from gpu_check import *\n",
    "#from data_load import *\n",
    "#from tf_ksom import *\n",
    "#from label import *\n",
    "#from test import *\n",
    "\n",
    "# hyper-parameters\n",
    "train_data = 60000\n",
    "label_data = 600\n",
    "test_data = 10000\n",
    "input_dim = 400 #784\n",
    "map_wth = 2\n",
    "map_hgt = 2\n",
    "map_dpt = 2\n",
    "class_nbr = 10\n",
    "nbr_epochs = 40 # 20\n",
    "eps_i_list = [1.0]\n",
    "eps_f_list = [0.01]\n",
    "eta_i_list = [10.0]\n",
    "eta_f_list = [0.01]\n",
    "sigma_kernel = 1.0\n",
    "\n",
    "# GPU name\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    raise SystemError(\"GPU device not found!\")\n",
    "print('Found GPU at: {}'.format(device_name))\n",
    "\n",
    "##\n",
    "## So, what if theres not test data\n",
    "##\n",
    "# load dataset\n",
    "# x_train, index_train, x_label, index_label, x_test, index_test, label_data = get_dataset(train_data, label_data, test_data)\n",
    "index_train, x_label, index_label, x_test, index_test, label_data = False, False, False, False, False, False\n",
    "x_train = npdf1\n",
    "\n",
    "##\n",
    "## make the ref from outside scope\n",
    "##\n",
    "som = []\n",
    "\n",
    "##\n",
    "## how the hell\n",
    "##\n",
    "# false run_som(false, false, false, eta_f):\n",
    "def run_som(eps_i, eps_f, eta_i, eta_f):\n",
    "    print(\"\\nHyper-parameters:   # eps_i = %f   # eps_f = %f   # eta_i = %f   # eta_f = %f\" % (eps_i, eps_f, eta_i, eta_f))\n",
    "    # train the network\n",
    "    som = KSOM_3D(map_wth, map_hgt, map_dpt, input_dim)\n",
    "    start_time = timeit.default_timer()\n",
    "    som.train(nbr_epochs, eps_i, eps_f, eta_i, eta_f, x_train, x_label, index_label, x_test, index_test)\n",
    "    end_time = timeit.default_timer()\n",
    "    print(\"\\nSOM training time = \", end_time - start_time)\n",
    "    weights = som.get_weights().numpy()\n",
    "\n",
    "    # save the weights\n",
    "    #np.save(\"weights/som_weights.npy\", weights)\n",
    "\n",
    "    ##\n",
    "    ## Now you no label\n",
    "    ##\n",
    "    # label the network\n",
    "    #neuron_label = labeling(label_data, class_nbr, weights, x_label, index_label, sigma_kernel)\n",
    "    neuron_label = False\n",
    "\n",
    "    ##\n",
    "    ## Now you no accuracy\n",
    "    # test the network\n",
    "    #accuracy = test(class_nbr, weights, x_test, index_test, neuron_label, sigma_kernel)\n",
    "    accuracy = False\n",
    "\n",
    "    return weights, accuracy\n",
    "\n",
    "# hyper-parameters grid search\n",
    "hyper_param_list, accuracy_list = [], []\n",
    "for eps_i in eps_i_list:\n",
    "    for eps_f in eps_f_list:\n",
    "        for eta_i in eta_i_list:\n",
    "            for eta_f in eta_f_list:\n",
    "                hyper_param_list.append([eps_i, eps_f, eta_i, eta_f])\n",
    "                weights, accuracy = run_som(eps_i, eps_f, eta_i, eta_f)\n",
    "                accuracy_list.append(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QgK04WK4OlOl"
   },
   "outputs": [],
   "source": [
    "# display neurons weights as time series\n",
    "som_grid = plt.figure(figsize=(10, 10)) # width, height in inches\n",
    "for i in range(map_wth):\n",
    "  for j in range(map_hgt):\n",
    "    for k in range(map_dpt):\n",
    "      sub = som_grid.add_subplot(map_wth, map_hgt, 2*j+i+1)\n",
    "      #image = weights[n].reshape([28,28]) # x_train[num] is the 784 normalized pixel values\n",
    "      sub.set_axis_off()\n",
    "      clr = sub.plot(range(400),weights[4*k+2*i+j],k)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g3RWKnXtQef_"
   },
   "source": [
    "Certo... analisando rapidamente...\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td>\n",
    "      1,1, azul eh 0-ply e verde 90-ply\n",
    "    </td>\n",
    "    <td>\n",
    "      1,2, azul eh 0-ply e verde 90-ply\n",
    "    </td>\n",
    "  </tr>\n",
    "\n",
    "  <tr>\n",
    "    <td>\n",
    "      2,1, azul eh +-45-ply e verde 0-ply<br>\n",
    "      ou<br>\n",
    "      2,1, azul eh 90-ply invertido e verrde eh +-45-ply\n",
    "    </td>\n",
    "    <td>\n",
    "      2,2, azul eh 0-ply e verde +-45-ply\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZQAp2fXycQrl"
   },
   "outputs": [],
   "source": [
    "# display neurons weights as time series\n",
    "som_grid = plt.figure(figsize=(10, 10)) # width, height in inches\n",
    "for i in range(map_wth):\n",
    "  for j in range(map_hgt):\n",
    "    sub = som_grid.add_subplot(map_wth*map_dpt, map_hgt, 4*k+2*i+j+1,projection='3d')\n",
    "    for k in range(map_dpt):\n",
    "        #image = weights[n].reshape([28,28]) # x_train[num] is the 784 normalized pixel values\n",
    "        sub.set_axis_off()\n",
    "        clr = sub.plot(range(400),weights[4*k+2*i+j],k)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5RuFt42GcPdl"
   },
   "outputs": [],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZNYi3C9Baqhy"
   },
   "source": [
    "# 4. Unified Distance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M_PuuA66awrC"
   },
   "outputs": [],
   "source": [
    "plt.imshow(umat, cmap=plt.cm.get_cmap('RdYlBu_r'), alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zDxNV1DSTtY6"
   },
   "outputs": [],
   "source": [
    "## hyper parameters below\n",
    "## label list below\n",
    "\n",
    "# GPU memory check\n",
    "gpu_report()\n",
    "\n",
    "# display neurons weights as mnist digits\n",
    "som_grid = plt.figure(figsize=(10, 10)) # width, height in inches\n",
    "for n in range(map_wth*map_hgt):\n",
    "    ##\n",
    "    ## Must make this into time series plot. Shouldnt be the thing\n",
    "    ##\n",
    "    #image = weights[n].reshape([28,28]) # x_train[num] is the 784 normalized pixel values\n",
    "    sub = som_grid.add_subplot(map_wth, map_hgt, n + 1)\n",
    "    sub.set_axis_off()\n",
    "    clr = sub.plot(weights[n]) # imshow(image, cmap = plt.get_cmap(\"jet\"), interpolation = \"nearest\")\n",
    "    #plt.colorbar(clr)\n",
    "#plt.savefig(\"plots/som_weights.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NeH9yjdK_ZNH"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aAr9vET5vnhJ"
   },
   "outputs": [],
   "source": [
    "plt.savefig(\"plots/som_weights.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kqnjan3e_AxL"
   },
   "outputs": [],
   "source": [
    "\n",
    "# best hyper-parameters\n",
    "best_accuracy = np.max(accuracy_list)\n",
    "best_hyper_param = hyper_param_list[np.argmax(accuracy_list)]\n",
    "print(\"Best accuracy = \", best_accuracy)\n",
    "print(\"Best hyper-parameters:   # eps_i = %f   # eps_f = %f   # sig_i = %f   # sig_f = %f\" % (best_hyper_param[0], best_hyper_param[1], best_hyper_param[2], best_hyper_param[3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hxJKrd6DxI00"
   },
   "outputs": [],
   "source": [
    "label_list = [label_data]\n",
    "for label_data in label_list:\n",
    "    print(\"\\n---------- Labels = %d ----------\" % label_data)\n",
    "    run_labeling(weights, label_data, x_train, index_train, x_test, index_test)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPz3VuuhDYrkt+fz96WCVgq",
   "collapsed_sections": [
    "6HE59u21zTIk",
    "9aKLEdkJybYY",
    "9fjgBClYqe3_",
    "ASSJ_UW80c4P",
    "ZhC_hROXtd7w",
    "YUp4My6JvezM",
    "E5SLZJdjz9Xi",
    "BOHsSjPUAvmU",
    "bA4o_Y2wqmfT",
    "-9TGxfebS4MX",
    "LuhmAyOyriAz",
    "Izaw5vm7N6EW",
    "ZNYi3C9Baqhy"
   ],
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
